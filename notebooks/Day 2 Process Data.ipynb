{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Day 2 Process Data.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"RHA88Oo_1JEz","colab_type":"text"},"source":["# Data Processing\n","\n","- Load image data using PyTorch\n","- Image transformations\n","- Preprocess images (resize, crop, normalize)"]},{"cell_type":"markdown","metadata":{"id":"MAerAjY6aeYg","colab_type":"text"},"source":["### Setup drive"]},{"cell_type":"markdown","metadata":{"id":"BY8phsHYdicZ","colab_type":"text"},"source":["Run the following cell to mount your Drive onto Colab. Go to the given URL and once you login and copy and paste the authorization code, you should see \"drive\" pop up in the files tab on the left."]},{"cell_type":"code","metadata":{"id":"hurAYstF1TVc","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RzP9vRERdmst","colab_type":"text"},"source":["Click the little triangle next to \"drive\" and navigate to the \"AI4All Chest X-Ray Project\" folder. Hover over the folder and click the 3 dots that appear on the right. Select \"copy path\" and replace `PASTE PATH HERE` with the path to your folder."]},{"cell_type":"code","metadata":{"id":"9kac1-X-cXhZ","colab_type":"code","colab":{}},"source":["cd \"PASTE PATH HERE\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YoRfQsJE493A","colab_type":"text"},"source":["### Import necessary libraries\n","Torchvision, or the PyTorch package, consists of popular datasets, model architectures, and common image transformations for computer vision."]},{"cell_type":"code","metadata":{"id":"y7qYM0a61JE2","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","\n","from torch.utils.data import random_split, Subset\n","\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","from utils.plotting import imshow_dataset\n","from utils.datahelper import calc_dataset_stats, get_random_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FlNKHL6V1JFD","colab_type":"text"},"source":["### Setup paths\n","Define paths and load metadata"]},{"cell_type":"code","metadata":{"id":"JurkCoKd1JFF","colab_type":"code","colab":{}},"source":["path_to_dataset = os.path.join('data')\n","\n","path_to_images = os.path.join(path_to_dataset, 'images')\n","\n","metadata = pd.read_csv(os.path.join(path_to_dataset, 'metadata_train.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RDefUUni1JFO","colab_type":"text"},"source":["### Load images"]},{"cell_type":"markdown","metadata":{"id":"NWu981cD1JFb","colab_type":"text"},"source":["**Pytorch loads the data using sub-folder names as class labels**\n","\n","Navigate to the \"images\" folder to see what this means.\n"]},{"cell_type":"code","metadata":{"id":"7K9vxOog8phL","colab_type":"code","colab":{}},"source":["dataset = datasets.ImageFolder(path_to_images, transform=None)\n","dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jl4WNZ41JFo","colab_type":"code","colab":{}},"source":["# EXERCISE: Use the function .class_to_idx to see what our classes are\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WpUeGWTj83pJ","colab_type":"text"},"source":["**Now let's take a look at the images themselves!**\n","\n","Note: The `imshow_dataset` function is defined in the file `utils/plotting.py`."]},{"cell_type":"code","metadata":{"id":"4-5t6y8x1JFP","colab_type":"code","colab":{}},"source":["# plots the first 5 images\n","imshow_dataset(dataset, n=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4-eKm8oweTiY","colab_type":"code","colab":{}},"source":["# plots 5 random images\n","imshow_dataset(dataset, n=5, rand=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fng1sPXc9Jak","colab_type":"text"},"source":["> **Discuss with each other**\n",">\n","> What do you notice about the images? What are their dimensions?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aC0ylzSJ_ilu","colab_type":"text"},"source":["### Transformations\n","The transforms module in PyTorch defines various transformations that can be performed on an image. \n","\n","Image transformations are used to pre-process images\n","as well as to \"augment\" the data. (We will discuss data augmentation in another section.)\n"]},{"cell_type":"markdown","metadata":{"id":"E77sTYbmhxUY","colab_type":"text"},"source":["**Resize the image using transforms**"]},{"cell_type":"code","metadata":{"id":"TxVrO7is_tnn","colab_type":"code","colab":{}},"source":["# get a random image from the dataset and resize it\n","im = get_random_image(dataset)\n","im = transforms.Resize(100)(im)\n","im"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IzaCwPplAnS_","colab_type":"code","colab":{}},"source":["transforms.Resize(50)(im)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9kgklEULi8ac","colab_type":"text"},"source":["**Try out other transformations**\n","\n","How do these transformations alter the image?\n","- `transforms.ColorJitter`\n","- `transforms.RandomAffine`\n","- `transforms.RandomHorizontalFlip`  \n","\n","You can [read more about these transformations here](https://pytorch.org/docs/stable/torchvision/transforms.html)\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"wUfx08Koi6SV","colab_type":"code","colab":{}},"source":["# EXERCISE: Apply different transformations to images and check out the output\n","#\n","# HINT: Use the code above as an example and try transforms functions such as RandomAffine\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPdzvLOgljle","colab_type":"text"},"source":["> **Discuss with each other**\n","> \n","> Which transformations could be useful to normalize the dataset? Which transformations could be useful to add diversity to data set?"]},{"cell_type":"markdown","metadata":{"id":"nvscfnfU1JFu","colab_type":"text"},"source":["### Examine image dimensions"]},{"cell_type":"markdown","metadata":{"id":"bDKayhybj9wJ","colab_type":"text"},"source":["Run the code below to calculate the image dimension.\n","\n","> **Discuss with each other**\n",">\n","> Based on the image dimension, are the images greyscale or color images?"]},{"cell_type":"code","metadata":{"id":"tKuIS_OF1JFv","colab_type":"code","colab":{}},"source":["im_sizes = [d[0].size for d in dataset]\n","\n","dimensions = set([len(s) for s in im_sizes])\n","\n","print(f'Dimensions in dataset: {dimensions}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CkWTitgFkXjq","colab_type":"text"},"source":["Compare x-ray images to another image"]},{"cell_type":"code","metadata":{"id":"kfqdczpxbOLq","colab_type":"code","colab":{}},"source":["# Answer the above question before running this block!\n","\n","from skimage import io\n","color_image = io.imread('https://unsplash.com/photos/twukN12EN7c/download')\n","io.imshow(color_image)\n","print(f'Random color image shape: {color_image.shape}')\n","print(f'Random xray image shape: {get_random_image(dataset).size}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwBVMapR1JF5","colab_type":"text"},"source":["**How much do image shapes and sizes vary in the dataset?**\n","\n","Run the code below to print the image dimensions for a set of random images"]},{"cell_type":"code","metadata":{"id":"EeawbFJC1JF6","colab_type":"code","colab":{}},"source":["im_num = 10\n","rand_indices = random.sample(range(len(dataset)), im_num)\n","subset = Subset(dataset, rand_indices)\n","\n","print(f'Image dimensions for {im_num} random images')\n","for d in subset:\n","    print(d[0].size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UO6YUmYBrt5N","colab_type":"text"},"source":["**Smallest dimension measurements**\n","\n","Calculate the smallest image width and height in the dataset."]},{"cell_type":"code","metadata":{"id":"NwR2WGDir1tp","colab_type":"code","colab":{}},"source":["# EXERCISE: calculate the smallest image width and smallest image height in the\n","# dataset\n","#\n","# HINT: look at blocks above for useful code, use min() to find minimum in a list\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SFMboM51mNWD","colab_type":"text"},"source":["> **Discuss with each other**\n","> \n","> How should we resize and crop the images? How do the smallest image width and smallest image height constrain our strategy?"]},{"cell_type":"markdown","metadata":{"id":"w2zW9QWB1JGN","colab_type":"text"},"source":["### Resize and crop"]},{"cell_type":"markdown","metadata":{"id":"83D3utI1mFGh","colab_type":"text"},"source":["To make the images the same shape and size for the learning model, we can apply image transformations when loading the data.\n","\n","The `transforms.Compose` function puts together a list of image transformations, which are applied in order to the images."]},{"cell_type":"code","metadata":{"id":"DzyqD6yJ1JGO","colab_type":"code","colab":{}},"source":["# EXERCISE: set resize and crop parameters based on your observations above\n","\n","resize_value = # HERE #\n","crop_value = # HERE #\n","\n","\n","# compose transformations\n","data_transforms = transforms.Compose([\n","        transforms.Resize(resize_value),\n","        transforms.CenterCrop(crop_value)])\n","\n","dataset = datasets.ImageFolder(path_to_images, transform=data_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4ZiIi7Lmv4e","colab_type":"code","colab":{}},"source":["# EXERCISE: compare the images with and without transformation applied. \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0C8N8lRZm9FC","colab_type":"code","colab":{}},"source":["# EXERCISE: try applying another list of transformations and compare the results\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u856kmgx1JGT","colab_type":"text"},"source":["### Normalize images"]},{"cell_type":"markdown","metadata":{"id":"q7UI9MUn1JGW","colab_type":"text"},"source":["**Calculate the pixel intensity mean and standard deviation across all images in the dataset.**\n","\n","Note: This code takes some time to run. The output is \n","\n","- Mean: 0.544\n","- Standard Deviation: 0.237"]},{"cell_type":"code","metadata":{"id":"tORr1xbH1JGX","colab_type":"code","colab":{}},"source":["data_transforms = transforms.Compose([\n","        transforms.Resize(resize_value),\n","        transforms.CenterCrop(crop_value),\n","        transforms.ToTensor()])\n","\n","dataset = datasets.ImageFolder(path_to_images, transform=data_transforms)\n","\n","data_mean, data_std = calc_dataset_stats(dataset)\n","print(f'Mean: {data_mean:.3f}, Standard Deviation: {data_std:.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t-PKVJ1R1JGg","colab_type":"text"},"source":["**Add normalization to the transformation list**\n","\n","The normalization step is applied on tensors and so is added after the `transforms.ToTensor` step. "]},{"cell_type":"code","metadata":{"id":"nW9X6mR31JGh","colab_type":"code","colab":{}},"source":["data_transforms = transforms.Compose([\n","        transforms.Grayscale(),\n","        transforms.Resize(resize_value),\n","        transforms.CenterCrop(crop_value),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[data_mean], std=[data_std])])\n","\n","dataset = datasets.ImageFolder(path_to_images, transform=data_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ElIWlR4dp7zf","colab_type":"code","colab":{}},"source":["# EXERCISE: compare the images with all the transformations applied.\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MP4a2Uly1JGs","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}